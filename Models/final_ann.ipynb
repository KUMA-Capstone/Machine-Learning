{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "   def __init__(self):\n",
    "      pass\n",
    "\n",
    "   def split_activities(self, data, col_activities):\n",
    "      data_new = data[col_activities].str.split(' \\| ', expand=True)\n",
    "      data_new.columns = ['col' + str(i) for i in range(1, len(data_new.columns)+1)]\n",
    "      return data_new\n",
    "\n",
    "   def make_unique_activities(self, data, clust_dict):\n",
    "      for col in data.columns:\n",
    "         data[col] = data[col].apply(lambda x: x.strip().lower() if pd.notna(x) else x)\n",
    "         data[col] = data[col].map({item: cluster for cluster, activity_list in clust_dict.items() for item in activity_list})\n",
    "\n",
    "      data_unique = pd.DataFrame()\n",
    "\n",
    "      for row in range(len(data)):\n",
    "         unique_values = data.iloc[row].unique()\n",
    "         df_row = pd.DataFrame(unique_values).T\n",
    "         data_unique = pd.concat([data_unique, df_row], ignore_index=True)\n",
    "\n",
    "      \n",
    "      data_unique.rename(columns={i: 'activity_'+str(i+1) for i in range(data_unique.shape[1])}, inplace=True)\n",
    "      return data_unique\n",
    "\n",
    "   def combine_to_first_data_and_drop(self, first_data, second_data, drop_feature):\n",
    "      df_combined = first_data.join(second_data)\n",
    "      df_combined.drop(drop_feature, axis=1, inplace=True)\n",
    "      df_combined['sub_mood'] = df_combined['sub_mood'].str.capitalize()\n",
    "      df_combined['sub_mood'] = df_combined['sub_mood'].str.strip()\n",
    "      return df_combined\n",
    "\n",
    "   def add_new_feature_is_weekend(self, data, new_feature):\n",
    "      data[new_feature] = np.where((data['weekday'] == 'Saturday') | (data['weekday'] == 'Sunday'), 1, 0)\n",
    "      return data\n",
    "\n",
    "   def fill_activities(self, data, column):\n",
    "      data = data[data[column].notna()]\n",
    "      data = data.fillna(value=0)\n",
    "      return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModeling:\n",
    "   def __init__(self):\n",
    "      self.ce = ce.OrdinalEncoder(cols=['mood'], mapping=[{'col': 'mood', 'mapping': {'Awful': 0, 'Bad': 1, 'Normal': 2, 'Good': 3, 'Amazing': 4}}])\n",
    "      self.smote = SMOTE()\n",
    "      self.model_ann = None\n",
    "\n",
    "   def split_data(self, data, train_prop, test_prop, label):\n",
    "      train_size = int(train_prop * len(data))\n",
    "\n",
    "      shuffled_index = random.sample(range(len(data)), len(data))\n",
    "\n",
    "      train_ann = data.iloc[shuffled_index[:train_size]]\n",
    "      test_ann = data.iloc[shuffled_index[train_size:]]\n",
    "\n",
    "      X_train = train_ann.drop(columns=label)\n",
    "      y_train = train_ann[label]\n",
    "      X_test = test_ann.drop(columns=label)\n",
    "      y_test = test_ann[label]\n",
    "\n",
    "      return X_train, X_test, y_train, y_test\n",
    "\n",
    "   def encoding(self, X_train, X_test, y_train, y_test):\n",
    "      X_train = pd.get_dummies(X_train)\n",
    "      X_test = pd.get_dummies(X_test)\n",
    "\n",
    "      y_train = self.ce.fit_transform(y_train)\n",
    "      y_test = self.ce.transform(y_test)\n",
    "\n",
    "      return X_train, X_test, y_train, y_test\n",
    "   \n",
    "   def add_columns_X(self, X, list_columns):\n",
    "      for num in range(1,9):\n",
    "         for item in list_columns:\n",
    "            if 'activity_'+str(num)+'_'+item not in X.columns:\n",
    "               X['activity_'+str(num)+'_'+item] = 0\n",
    "      return X\n",
    "\n",
    "   def add_missing_column(self, X_train, X_test, y_train, y_test):\n",
    "      # Add missing columns to X_train and fill with value 0\n",
    "      missing_cols_train = set(X_test.columns) - set(X_train.columns)\n",
    "      for col in missing_cols_train:\n",
    "         X_train[col] = 0\n",
    "\n",
    "      # Add missing columns to X_test and fill with value 0\n",
    "      missing_cols_test = set(X_train.columns) - set(X_test.columns)\n",
    "      for col in missing_cols_test:\n",
    "         X_test[col] = 0\n",
    "\n",
    "      # Make sure column order is the same\n",
    "      X_train = X_train.reindex(sorted(X_train.columns), axis=1)\n",
    "      X_test = X_test.reindex(sorted(X_test.columns), axis=1)\n",
    "\n",
    "      return X_train, X_test, y_train, y_test\n",
    "   \n",
    "   def apply_oversampling(self, X_train, y_train):\n",
    "      X_train, y_train = self.smote.fit_resample(X_train, y_train)\n",
    "      return X_train, y_train\n",
    "   \n",
    "   def build_ann_model(self, input_dim):\n",
    "      self.model_ann = Sequential()\n",
    "      self.model_ann.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "      self.model_ann.add(Dense(64, activation='relu'))\n",
    "      self.model_ann.add(Dropout(0.5))\n",
    "      self.model_ann.add(Dense(len(self.ce.mapping[0]['mapping']), activation='softmax'))\n",
    "      self.model_ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "   def train_model_ann(self, y_train, y_test):\n",
    "      y_train = to_categorical(y_train)\n",
    "      y_test = to_categorical(y_test)\n",
    "      return y_train, y_test\n",
    "   \n",
    "   def train_model(self, X_train, y_train, input_dim, epochs=100, batch_size=32, validation_data=None):\n",
    "      self.build_ann_model(input_dim),\n",
    "      self.model_ann.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "   \n",
    "   def predict(self, X_test):\n",
    "      y_pred = self.model_ann.predict(X_test)\n",
    "      return y_pred\n",
    "\n",
    "   def evaluate(self, X_test, y_test):\n",
    "      y_pred = self.predict(X_test)\n",
    "      y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "      y_true = np.argmax(y_test, axis=1)\n",
    "      accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "      report = classification_report(y_true, y_pred_classes)\n",
    "      return accuracy, report\n",
    "    \n",
    "   def save_models(self, name_model):\n",
    "      return self.model_ann.save(name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_date</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "      <th>sub_mood</th>\n",
       "      <th>activities</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/04/2021</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8:00 pm</td>\n",
       "      <td>yolo</td>\n",
       "      <td>reading | Art | prayer | fasting  | walk | med...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/04/2021</td>\n",
       "      <td>Apr-15</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2:37 am</td>\n",
       "      <td>focused</td>\n",
       "      <td>reading | learning  | Art | prayer | fasting  ...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/04/2021</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2:39 am</td>\n",
       "      <td>confused</td>\n",
       "      <td>reading | learning  | prayer | fasting  | Qura...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/04/2021</td>\n",
       "      <td>Apr-13</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2:38 am</td>\n",
       "      <td>wondering</td>\n",
       "      <td>reading | learning  | Art | prayer | fasting  ...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/04/2021</td>\n",
       "      <td>Apr-12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>9:52 pm</td>\n",
       "      <td>angry</td>\n",
       "      <td>reading | learning  | fasting  | walk | medita...</td>\n",
       "      <td>Awful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    full_date    date    weekday     time   sub_mood  \\\n",
       "0  16/04/2021  Apr-16     Friday  8:00 pm       yolo   \n",
       "1  15/04/2021  Apr-15   Thursday  2:37 am   focused    \n",
       "2  14/04/2021  Apr-14  Wednesday  2:39 am  confused    \n",
       "3  13/04/2021  Apr-13    Tuesday  2:38 am  wondering   \n",
       "4  12/04/2021  Apr-12     Monday  9:52 pm      angry   \n",
       "\n",
       "                                          activities    mood  \n",
       "0  reading | Art | prayer | fasting  | walk | med...    Good  \n",
       "1  reading | learning  | Art | prayer | fasting  ...    Good  \n",
       "2  reading | learning  | prayer | fasting  | Qura...  Normal  \n",
       "3  reading | learning  | Art | prayer | fasting  ...  Normal  \n",
       "4  reading | learning  | fasting  | walk | medita...   Awful  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Pribadi\\Bangkit\\Capstone\\Daylio_Abid.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sub_mood'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataProcessor()\n",
    "# split aktivitas\n",
    "df_new = processor.split_activities(df, 'activities')\n",
    "\n",
    "# buat unique value aktivitas\n",
    "clust_dict = {\n",
    "    'Reading and Learning': ['research', 'reading', 'learning', 'language learning', 'news update', 'coding'],\n",
    "    'Spiritual': ['quran', 'prayer', 'kaballah', 'meditation', 'holotropic', 'fasting'],\n",
    "    'Social': ['friends', 'party', 'family', 'penpal', 'shopping'],\n",
    "    'Physical and Travel': ['exercise', 'travel', 'walk', 'hiking'],\n",
    "    'Self-pleasure and Entertainment': ['gaming', 'reddit', 'watching series', 'audio books', 'streaming', 'dota 2', 'movies', 'songs', 'podcast', 'youtube', 'shower', 'trimming', 'shave', 'good meal', 'power nap'],\n",
    "    'Creative': ['writing', 'art', 'poetry', 'designing', 'recording', 'video editing', 'documentary', 'write dairy'],\n",
    "    'Home': ['cleaning', 'cooking'],\n",
    "    'Other': ['weight log', 'love', 'jobs', 'tutorial', 'new things', 'phd', 'email', 'repair']\n",
    "    }\n",
    "df_new = processor.make_unique_activities(df_new, clust_dict)\n",
    "\n",
    "# Combine data\n",
    "list_drop = ['activities', 'full_date', 'date', 'time', 'activity_9']\n",
    "df_new = processor.combine_to_first_data_and_drop(df, df_new, list_drop)\n",
    "\n",
    "# Add new feature\n",
    "df_new = processor.add_new_feature_is_weekend(df_new, 'is_weekend')\n",
    "\n",
    "# Fill activities\n",
    "df_new = processor.fill_activities(df_new, 'activity_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 4ms/step - loss: 1.5054 - accuracy: 0.3393 - val_loss: 1.3619 - val_accuracy: 0.5261\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.2358 - accuracy: 0.5613 - val_loss: 1.0300 - val_accuracy: 0.6903\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.9029 - accuracy: 0.7135 - val_loss: 0.6221 - val_accuracy: 0.8731\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.8245 - val_loss: 0.2729 - val_accuracy: 0.9701\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8773 - val_loss: 0.1395 - val_accuracy: 0.9813\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8951 - val_loss: 0.0909 - val_accuracy: 0.9851\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.9147 - val_loss: 0.0553 - val_accuracy: 0.9888\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9110 - val_loss: 0.0504 - val_accuracy: 0.9851\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9252 - val_loss: 0.0454 - val_accuracy: 0.9851\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9215 - val_loss: 0.0375 - val_accuracy: 0.9851\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9301 - val_loss: 0.0308 - val_accuracy: 0.9925\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9399 - val_loss: 0.0235 - val_accuracy: 0.9963\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9344 - val_loss: 0.0262 - val_accuracy: 0.9925\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9417 - val_loss: 0.0233 - val_accuracy: 0.9888\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9393 - val_loss: 0.0192 - val_accuracy: 0.9925\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9387 - val_loss: 0.0205 - val_accuracy: 0.9925\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9454 - val_loss: 0.0200 - val_accuracy: 0.9925\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9479 - val_loss: 0.0168 - val_accuracy: 0.9925\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9546 - val_loss: 0.0145 - val_accuracy: 0.9925\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9509 - val_loss: 0.0163 - val_accuracy: 0.9925\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9540 - val_loss: 0.0135 - val_accuracy: 0.9925\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9485 - val_loss: 0.0119 - val_accuracy: 0.9963\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9571 - val_loss: 0.0162 - val_accuracy: 0.9925\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9595 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9558 - val_loss: 0.0178 - val_accuracy: 0.9963\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9613 - val_loss: 0.0179 - val_accuracy: 0.9925\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9601 - val_loss: 0.0230 - val_accuracy: 0.9925\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9577 - val_loss: 0.0131 - val_accuracy: 0.9963\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9644 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9620 - val_loss: 0.0143 - val_accuracy: 0.9963\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9632 - val_loss: 0.0124 - val_accuracy: 0.9963\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9583 - val_loss: 0.0104 - val_accuracy: 0.9963\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9632 - val_loss: 0.0153 - val_accuracy: 0.9963\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9613 - val_loss: 0.0146 - val_accuracy: 0.9963\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9675 - val_loss: 0.0117 - val_accuracy: 0.9963\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9638 - val_loss: 0.0122 - val_accuracy: 0.9963\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9669 - val_loss: 0.0132 - val_accuracy: 0.9963\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.0078 - val_accuracy: 0.9963\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9650 - val_loss: 0.0085 - val_accuracy: 0.9963\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9724 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9669 - val_loss: 0.0087 - val_accuracy: 0.9963\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9669 - val_loss: 0.0066 - val_accuracy: 0.9963\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9736 - val_loss: 0.0130 - val_accuracy: 0.9963\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9687 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9712 - val_loss: 0.0087 - val_accuracy: 0.9963\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9681 - val_loss: 0.0118 - val_accuracy: 0.9963\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.0081 - val_accuracy: 0.9963\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9663 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.0149 - val_accuracy: 0.9963\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9663 - val_loss: 0.0099 - val_accuracy: 0.9963\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9755 - val_loss: 0.0093 - val_accuracy: 0.9963\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9718 - val_loss: 0.0159 - val_accuracy: 0.9963\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 0.0170 - val_accuracy: 0.9963\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9687 - val_loss: 0.0155 - val_accuracy: 0.9963\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9730 - val_loss: 0.0200 - val_accuracy: 0.9963\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9706 - val_loss: 0.0192 - val_accuracy: 0.9963\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9706 - val_loss: 0.0211 - val_accuracy: 0.9963\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9699 - val_loss: 0.0155 - val_accuracy: 0.9963\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9687 - val_loss: 0.0129 - val_accuracy: 0.9963\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9755 - val_loss: 0.0236 - val_accuracy: 0.9963\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.0200 - val_accuracy: 0.9963\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9712 - val_loss: 0.0151 - val_accuracy: 0.9963\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9730 - val_loss: 0.0105 - val_accuracy: 0.9963\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9699 - val_loss: 0.0187 - val_accuracy: 0.9963\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 0.0192 - val_accuracy: 0.9963\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9730 - val_loss: 0.0189 - val_accuracy: 0.9963\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9706 - val_loss: 0.0200 - val_accuracy: 0.9963\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9730 - val_loss: 0.0250 - val_accuracy: 0.9963\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9773 - val_loss: 0.0103 - val_accuracy: 0.9963\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9724 - val_loss: 0.0190 - val_accuracy: 0.9963\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9718 - val_loss: 0.0271 - val_accuracy: 0.9963\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9706 - val_loss: 0.0204 - val_accuracy: 0.9963\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.0247 - val_accuracy: 0.9963\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9736 - val_loss: 0.0247 - val_accuracy: 0.9963\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9730 - val_loss: 0.0330 - val_accuracy: 0.9963\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9736 - val_loss: 0.0154 - val_accuracy: 0.9963\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9712 - val_loss: 0.0179 - val_accuracy: 0.9963\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9736 - val_loss: 0.0206 - val_accuracy: 0.9963\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9699 - val_loss: 0.0207 - val_accuracy: 0.9963\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9761 - val_loss: 0.0306 - val_accuracy: 0.9963\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9730 - val_loss: 0.0160 - val_accuracy: 0.9963\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9712 - val_loss: 0.0287 - val_accuracy: 0.9963\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9742 - val_loss: 0.0222 - val_accuracy: 0.9963\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9706 - val_loss: 0.0195 - val_accuracy: 0.9963\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9773 - val_loss: 0.0272 - val_accuracy: 0.9963\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.0266 - val_accuracy: 0.9963\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 0.0274 - val_accuracy: 0.9963\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9730 - val_loss: 0.0221 - val_accuracy: 0.9963\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9712 - val_loss: 0.0199 - val_accuracy: 0.9963\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9767 - val_loss: 0.0294 - val_accuracy: 0.9963\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9761 - val_loss: 0.0224 - val_accuracy: 0.9963\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9724 - val_loss: 0.0285 - val_accuracy: 0.9963\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9742 - val_loss: 0.0299 - val_accuracy: 0.9963\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9724 - val_loss: 0.0302 - val_accuracy: 0.9963\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9712 - val_loss: 0.0209 - val_accuracy: 0.9963\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9755 - val_loss: 0.0188 - val_accuracy: 0.9963\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.0276 - val_accuracy: 0.9963\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9712 - val_loss: 0.0225 - val_accuracy: 0.9963\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9767 - val_loss: 0.0310 - val_accuracy: 0.9963\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9761 - val_loss: 0.0320 - val_accuracy: 0.9963\n"
     ]
    }
   ],
   "source": [
    "modeling = DataModeling()\n",
    "\n",
    "# Memisahkan data menjadi data pelatihan dan data pengujian\n",
    "X_train, X_test, y_train, y_test = modeling.split_data(df_new, train_prop=0.7, test_prop=0.3, label='mood')\n",
    "\n",
    "# Melakukan encoding variabel kategorikal pada data\n",
    "X_train, X_test, y_train, y_test = modeling.encoding(X_train, X_test, y_train, y_test)\n",
    "\n",
    "list_of_activity = list(clust_dict.keys())\n",
    "X_train = modeling.add_columns_X(X_train, list_of_activity)\n",
    "X_test = modeling.add_columns_X(X_test, list_of_activity)\n",
    "\n",
    "# Menambahkan kolom yang hilang pada data pelatihan dan data pengujian\n",
    "X_train, X_test, y_train, y_test = modeling.add_missing_column(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Menerapkan oversampling pada data pelatihan\n",
    "X_train, y_train = modeling.apply_oversampling(X_train, y_train)\n",
    "\n",
    "y_train, y_test = modeling.train_model_ann(y_train, y_test)\n",
    "\n",
    "# Memproses dan melatih model dengan data yang telah diproses\n",
    "modeling.train_model(X_train, y_train, input_dim=X_train.shape[1], epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.996268656716418\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        45\n",
      "           3       1.00      1.00      1.00       144\n",
      "           4       0.98      1.00      0.99        53\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      0.98      0.99       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeling.predict(X_test)\n",
    "\n",
    "accuracy, report = modeling.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.save_models('model_ann.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_activities(data, col_activities):\n",
    "    data_new = data[col_activities].str.split(' \\| ', expand=True)\n",
    "    data_new.columns = ['activity_'+str(i+1) for i in range(data_new.shape[1])]\n",
    "\n",
    "    return data_new\n",
    "\n",
    "def make_unique_activities(data, clust_dict):\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].apply(lambda x: x.strip().lower() if pd.notna(x) else x)\n",
    "        data[col] = data[col].map({item: cluster for cluster, activity_list in clust_dict.items() for item in activity_list})\n",
    "\n",
    "    data_unique = pd.DataFrame()\n",
    "\n",
    "    for row in range(len(data)):\n",
    "        unique_values = data.iloc[row].unique()\n",
    "        df_row = pd.DataFrame(unique_values).T\n",
    "        data_unique = pd.concat([data_unique, df_row], ignore_index=True)\n",
    "\n",
    "    data_unique.rename(columns={i: 'activity_'+str(i+1) for i in range(data_unique.shape[1])}, inplace=True)\n",
    "    return data_unique\n",
    "\n",
    "def combine_to_first_data_and_drop(first_data, second_data, drop_feature):\n",
    "    df_combined = first_data.join(second_data)\n",
    "    df_combined.drop(drop_feature, axis=1, inplace=True)\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "def add_new_feature_is_weekend(data, new_feature):\n",
    "    data[new_feature] = np.where((data['weekday'] == 'Saturday') | (data['weekday'] == 'Sunday'), 1, 0)\n",
    "    return data\n",
    "\n",
    "def fill_activities(data, column):\n",
    "    data = data[data[column].notna()]\n",
    "    data = data.fillna(value=0)\n",
    "    return data\n",
    "\n",
    "def encoding(data):\n",
    "    data = pd.get_dummies(data)\n",
    "    return data\n",
    "\n",
    "def add_columns_activity_data(data, list_columns):\n",
    "      for num in range(1,9):\n",
    "         for item in list_columns:\n",
    "            if 'activity_'+str(num)+'_'+item not in data.columns:\n",
    "               data['activity_'+str(num)+'_'+item] = 0\n",
    "            if num > 1:\n",
    "                data['activity_'+str(num)+'_'+'0'] = 0\n",
    "      return data\n",
    "\n",
    "def add_columns_submood_data(data, list_columns):\n",
    "    for item in list_columns:\n",
    "        if 'sub_mood_' + item not in data.columns:\n",
    "            data['sub_mood_' + item] = 0\n",
    "    return data\n",
    "\n",
    "def add_columns_weekday_data(data, list_columns):\n",
    "    for item in list_columns:\n",
    "        if 'weekday_'+item not in data.columns:\n",
    "            data['weekday_'+item] = 0\n",
    "    return data\n",
    "\n",
    "def preprocess(data):\n",
    "    df_new = split_activities(data, 'activities')\n",
    "\n",
    "    # buat unique value aktivitas\n",
    "    clust_dict = {\n",
    "        'Reading and Learning': ['research', 'reading', 'learning', 'language learning', 'news update', 'coding'],\n",
    "        'Spiritual': ['quran', 'prayer', 'kaballah', 'meditation', 'holotropic', 'fasting'],\n",
    "        'Social': ['friends', 'party', 'family', 'penpal', 'shopping'],\n",
    "        'Physical and Travel': ['exercise', 'travel', 'walk', 'hiking'],\n",
    "        'Self-pleasure and Entertainment': ['gaming', 'reddit', 'watching series', 'audio books', 'streaming', 'dota 2', 'movies', 'songs', 'podcast', 'youtube', 'shower', 'trimming', 'shave', 'good meal', 'power nap'],\n",
    "        'Creative': ['writing', 'art', 'poetry', 'designing', 'recording', 'video editing', 'documentary', 'write dairy'],\n",
    "        'Home': ['cleaning', 'cooking'],\n",
    "        'Other': ['weight log', 'love', 'jobs', 'tutorial', 'new things', 'phd', 'email', 'repair']\n",
    "        }\n",
    "    # df_new = make_unique_activities(df_new, clust_dict)\n",
    "\n",
    "    # gabung dat\n",
    "    list_drop = ['activities', 'full_date', 'date', 'time']\n",
    "    df_new = combine_to_first_data_and_drop(data, df_new, list_drop)\n",
    "\n",
    "    # Add new feature\n",
    "    df_new = add_new_feature_is_weekend(df_new, 'is_weekend')\n",
    "\n",
    "    # Fill activities\n",
    "    df_new = fill_activities(df_new, 'activity_1')\n",
    "    df_new = encoding(df_new)\n",
    "\n",
    "    # menambahkan kolom aktivitas\n",
    "    list_of_activity = list(clust_dict.keys())\n",
    "    df_new = add_columns_activity_data(df_new, list_of_activity)\n",
    "\n",
    "    # menambahkan kolom submood\n",
    "    list_of_submood = ['Yolo','Focused','Confused','Wondering','Angry','Blessed','Excited','Chill','Hungry','Happiest day',\n",
    "                       'Weak','Meh','Awful','Cool','Worried','Over the moon','Triggered','Sad af','Scared','Good','Bad','Sick']\n",
    "    df_new = add_columns_submood_data(df_new, list_of_submood)\n",
    "\n",
    "    # menambahkan kolom weekday\n",
    "    list_of_day = ['Friday', 'Thursday', 'Wednesday', 'Tuesday', 'Monday', 'Sunday', 'Saturday']\n",
    "    df_new = add_columns_weekday_data(df_new, list_of_day)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_inp = [\n",
    "    [\"16/04/2021\"], \n",
    "     [\"Apr-16\"], \n",
    "      [\"Sunday\"], \n",
    "       [\"8:00 pm\"], \n",
    "        [\"Cool\"], \n",
    "         [\"Reading and Learning | Self-pleasure and Entertainment | Social\"],\n",
    "        ]\n",
    "df_inp = pd.DataFrame(lst_inp).transpose()\n",
    "df_inp.columns=['full_date', 'date', 'weekday', 'time', 'sub_mood', 'activities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train = ['activity_1_Creative','activity_1_Home','activity_1_Other','activity_1_Physical and Travel','activity_1_Reading and Learning',\n",
    "            'activity_1_Self-pleasure and Entertainment','activity_1_Social','activity_1_Spiritual','activity_2_0','activity_2_Creative',\n",
    "            'activity_2_Home','activity_2_Other','activity_2_Physical and Travel','activity_2_Reading and Learning','activity_2_Self-pleasure and Entertainment',\n",
    "            'activity_2_Social','activity_2_Spiritual','activity_3_0','activity_3_Creative','activity_3_Home','activity_3_Other',\n",
    "            'activity_3_Physical and Travel','activity_3_Reading and Learning','activity_3_Self-pleasure and Entertainment','activity_3_Social',\n",
    "            'activity_3_Spiritual','activity_4_0','activity_4_Creative','activity_4_Home','activity_4_Other','activity_4_Physical and Travel',\n",
    "            'activity_4_Reading and Learning','activity_4_Self-pleasure and Entertainment','activity_4_Social','activity_4_Spiritual','activity_5_0',\n",
    "            'activity_5_Creative','activity_5_Home','activity_5_Other','activity_5_Physical and Travel','activity_5_Reading and Learning',\n",
    "            'activity_5_Self-pleasure and Entertainment','activity_5_Social','activity_5_Spiritual','activity_6_0','activity_6_Creative',\n",
    "            'activity_6_Home','activity_6_Other','activity_6_Physical and Travel','activity_6_Reading and Learning','activity_6_Self-pleasure and Entertainment',\n",
    "            'activity_6_Social','activity_6_Spiritual','activity_7_0','activity_7_Creative','activity_7_Home','activity_7_Other','activity_7_Physical and Travel',\n",
    "            'activity_7_Reading and Learning','activity_7_Self-pleasure and Entertainment','activity_7_Social','activity_7_Spiritual','activity_8_0',\n",
    "            'activity_8_Creative','activity_8_Home','activity_8_Other','activity_8_Physical and Travel','activity_8_Reading and Learning',\n",
    "            'activity_8_Self-pleasure and Entertainment','activity_8_Social','activity_8_Spiritual','is_weekend','sub_mood_Angry','sub_mood_Awful',\n",
    "            'sub_mood_Bad','sub_mood_Blessed','sub_mood_Chill','sub_mood_Confused','sub_mood_Cool','sub_mood_Excited','sub_mood_Focused','sub_mood_Good',\n",
    "            'sub_mood_Happiest day','sub_mood_Hungry','sub_mood_Meh','sub_mood_Over the moon','sub_mood_Sad af','sub_mood_Scared','sub_mood_Sick',\n",
    "            'sub_mood_Triggered','sub_mood_Weak','sub_mood_Wondering','sub_mood_Worried','sub_mood_Yolo','weekday_Friday','weekday_Monday',\n",
    "            'weekday_Saturday','weekday_Sunday','weekday_Thursday','weekday_Tuesday','weekday_Wednesday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 101)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = preprocess(df_inp)[col_train]\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ann = keras.models.load_model(\"D:\\Pribadi\\Bangkit\\Capstone\\model_ann.h5\")\n",
    "pred = model_ann.predict(result)\n",
    "np.argmax(pred, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_1_Creative', 'activity_1_Home', 'activity_1_Other',\n",
       "       'activity_1_Physical and Travel', 'activity_1_Reading and Learning',\n",
       "       'activity_1_Self-pleasure and Entertainment', 'activity_1_Social',\n",
       "       'activity_1_Spiritual', 'activity_2_0', 'activity_2_Creative',\n",
       "       ...\n",
       "       'sub_mood_Wondering', 'sub_mood_Worried', 'sub_mood_Yolo',\n",
       "       'weekday_Friday', 'weekday_Monday', 'weekday_Saturday',\n",
       "       'weekday_Sunday', 'weekday_Thursday', 'weekday_Tuesday',\n",
       "       'weekday_Wednesday'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_1_Creative', 'activity_1_Home', 'activity_1_Other',\n",
       "       'activity_1_Physical and Travel', 'activity_1_Reading and Learning',\n",
       "       'activity_1_Self-pleasure and Entertainment', 'activity_1_Social',\n",
       "       'activity_1_Spiritual', 'activity_2_0', 'activity_2_Creative',\n",
       "       ...\n",
       "       'sub_mood_Wondering', 'sub_mood_Worried', 'sub_mood_Yolo',\n",
       "       'weekday_Friday', 'weekday_Monday', 'weekday_Saturday',\n",
       "       'weekday_Sunday', 'weekday_Thursday', 'weekday_Tuesday',\n",
       "       'weekday_Wednesday'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- Karena inputan untuk activity dari user app nanti sudah sesuai, maka fungsi make_unique_activities sudah tidak diperlukan lagi\n",
    "- Buat fungsi yang sama pada weekday dan submood seperti fungsi add_columns_activity_data\n",
    "- Perhatikan pada data train, ada kolom aktivitas yang memiliki subjek 0\n",
    "\n",
    "DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-1fd1bc752ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m new_columns = ['Reading and Learning',\n\u001b[0;32m      4\u001b[0m  \u001b[1;34m'Spiritual'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m  \u001b[1;34m'Social'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_\n",
    "\n",
    "new_columns = ['Reading and Learning',\n",
    " 'Spiritual',\n",
    " 'Social',\n",
    " 'Physical and Travel',\n",
    " 'Self-pleasure and Entertainment',\n",
    " 'Creative',\n",
    " 'Home',\n",
    " 'Other']\n",
    "\n",
    "df.columns = new_columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reading and Learning</th>\n",
       "      <th>Spiritual</th>\n",
       "      <th>Social</th>\n",
       "      <th>Physical and Travel</th>\n",
       "      <th>Self-pleasure and Entertainment</th>\n",
       "      <th>Creative</th>\n",
       "      <th>Home</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "      <td>Reading and Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>Spiritual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "      <td>Physical and Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reading and Learning             Spiritual                Social  \\\n",
       "0  Reading and Learning  Reading and Learning  Reading and Learning   \n",
       "1             Spiritual             Spiritual             Spiritual   \n",
       "2                Social                Social                Social   \n",
       "3   Physical and Travel   Physical and Travel   Physical and Travel   \n",
       "\n",
       "    Physical and Travel Self-pleasure and Entertainment              Creative  \\\n",
       "0  Reading and Learning            Reading and Learning  Reading and Learning   \n",
       "1             Spiritual                       Spiritual             Spiritual   \n",
       "2                Social                          Social                Social   \n",
       "3   Physical and Travel             Physical and Travel   Physical and Travel   \n",
       "\n",
       "                   Home                 Other  \n",
       "0  Reading and Learning  Reading and Learning  \n",
       "1             Spiritual             Spiritual  \n",
       "2                Social                Social  \n",
       "3   Physical and Travel   Physical and Travel  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    for j in df.iloc[i].unique():\n",
    "        if j != df.columns[i]:\n",
    "            df.iloc[i] = df.iloc[i].replace(j, df.columns[i])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reading and Learning',\n",
       " 'Spiritual',\n",
       " 'Social',\n",
       " 'Physical and Travel',\n",
       " 'Self-pleasure and Entertainment',\n",
       " 'Creative',\n",
       " 'Home',\n",
       " 'Other']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clust_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
